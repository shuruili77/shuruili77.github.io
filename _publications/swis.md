---
title: "SWIS--Shared Weight bIt Sparsity for Efficient Neural Network Acceleration"
collection: publications
permalink: /publication/swis
excerpt: 'A systolic arrary design that implements bit-serial computation to remove multipliers and make the neural network execution more efficient.'
date: 2021-03-01
venue: 'TinyML Research Symposium (TinyML)'
paperurl: 'https://arxiv.org/pdf/2103.01308.pdf'
citation: 'Li, S., Romaszkan, W., Graening, A. and Gupta, P., 2021. SWIS--Shared Weight bIt Sparsity for Efficient Neural Network Acceleration. arXiv preprint arXiv:2103.01308'
---
A systolic arrary design that implements bit-serial computation to remove multipliers and make the neural network execution more efficient.

[Download paper here](https://arxiv.org/pdf/2103.01308.pdf)

BibTeX citation: 

@article{li2021swis,
  title={SWIS--Shared Weight bIt Sparsity for Efficient Neural Network Acceleration},
  author={Li, Shurui and Romaszkan, Wojciech and Graening, Alexander and Gupta, Puneet},
  journal={arXiv preprint arXiv:2103.01308},
  year={2021}
}