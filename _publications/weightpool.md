---
title: "Bit-serial Weight Pools: Compression and Arbitrary Precision Execution of Neural Networks on Resource Constrained Processors"
collection: publications
permalink: /publication/weightpool
excerpt: 'This paper present a framework to compress neural networks and execute them with arbitrary precision on resource constrained processors through weight sharing, bit-serial computation, and look up tables. '
date: 2022-01-25
venue: 'Conference on Machine Learning and Systems (MLSys)'
paperurl: 'https://proceedings.mlsys.org/paper_files/paper/2022/file/502e4a16930e414107ee22b6198c578f-Paper.pdf'
citation: 'Li, S. and Gupta, P., 2022. Bit-serial Weight Pools: Compression and Arbitrary Precision Execution of Neural Networks on Resource Constrained Processors. Proceedings of Machine Learning and Systems, 4, pp.238-250.'
---
This paper present a framework to compress neural networks and execute them with arbitrary precision on resource constrained processors through weight sharing, bit-serial computation, and look up tables. 

[Download paper here](https://proceedings.mlsys.org/paper_files/paper/2022/file/502e4a16930e414107ee22b6198c578f-Paper.pdf)

BibTeX citation:  

@inproceedings{MLSYS2022_502e4a16,
 author = {Li, Shurui and Gupta, Puneet},
 booktitle = {Proceedings of Machine Learning and Systems},
 editor = {D. Marculescu and Y. Chi and C. Wu},
 pages = {238--250},
 title = {Bit-serial Weight Pools: Compression and Arbitrary Precision Execution of Neural Networks on Resource Constrained Processors},
 url = {https://proceedings.mlsys.org/paper_files/paper/2022/file/502e4a16930e414107ee22b6198c578f-Paper.pdf},
 volume = {4},
 year = {2022}
}